#Ejercicio 1
#1.1 Crear desde sqoop dos tablas:
#     1.1.1  Desde Sqoop carga la tabla Customer de MySQL a hive 
#     1.1.2  Desde Sqoop cargar una tabla de MySQL en Hive creando la  desde el import de Sqoop.
#1.2 Desde spark scala realizar join entre las dos tablas de hive customerHive y Orders:
#     1.2.1  Calcular cuantos pedidos se realizan por ciudad y cliente
#     1.2.2  Cual es la cuidad que realiza mas pedidos.
#     1.2.3  Cuales son los clientes que mas compran por cuidad.
#     1.2.4  Cuales son los 10 mayores clientes.
#     1.2.5  Cual es el producto mas comprado por los clientes en cada cuidad
#     1.2.6  Cuales son los 10 productos mas comprados por los 5 mayores clientes.

#Ejercicio1
#1.1.1  Desde Sqoop carga la tabla Customer de MySQL a hive 
#############################################################
mysql> describe orders;
+-------------------+-------------+------+-----+---------+----------------+
| Field             | Type        | Null | Key | Default | Extra          |
+-------------------+-------------+------+-----+---------+----------------+
| order_id          | int(11)     | NO   | PRI | NULL    | auto_increment |
| order_date        | datetime    | NO   |     | NULL    |                |
| order_customer_id | int(11)     | NO   |     | NULL    |                |
| order_status      | varchar(45) | NO   |     | NULL    |                |
+-------------------+-------------+------+-----+---------+----------------+
mysql> describe customers;
+-------------------+--------------+------+-----+---------+----------------+
| Field             | Type         | Null | Key | Default | Extra          |
+-------------------+--------------+------+-----+---------+----------------+
| customer_id       | int(11)      | NO   | PRI | NULL    | auto_increment |
| customer_fname    | varchar(45)  | NO   |     | NULL    |                |
| customer_lname    | varchar(45)  | NO   |     | NULL    |                |
| customer_email    | varchar(45)  | NO   |     | NULL    |                |
| customer_password | varchar(45)  | NO   |     | NULL    |                |
| customer_street   | varchar(255) | NO   |     | NULL    |                |
| customer_city     | varchar(45)  | NO   |     | NULL    |                |
| customer_state    | varchar(45)  | NO   |     | NULL    |                |
| customer_zipcode  | varchar(45)  | NO   |     | NULL    |                |
+-------------------+--------------+------+-----+---------+----------------+

hive>  CREATE TABLE IF NOT EXISTS customersHive ( customer_id int, customer_city  String,
    >  customer_state String)
    >  COMMENT 'CustomersHive details'
    >  ROW FORMAT DELIMITED
    >  FIELDS TERMINATED BY '\t'
    >  LINES TERMINATED BY '\n'
    >  STORED AS TEXTFILE;
OK
Time taken: 0.676 seconds
hive> show tables;
OK
customershive
Time taken: 0.087 seconds, Fetched: 1 row(s)

sqoop import --connect jdbc:mysql://quickstart.cloudera:3306/retail_db --username root --password cloudera \
--split-by customer_id \
--columns customer_id,customer_city,customer_state \
--table customers \
--target-dir /user/cloudera/CustomersHive \
--fields-terminated-by "," \
--hive-import ;
Se crea una tabla HIVE EN LA RUTA /HIVE/WAREHOUSE/con el mismo nombre que tabla de mysql
Loading data to table default.customers
chgrp: changing ownership of 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/customers/part-m-00000': User does not belong to supergroup
chgrp: changing ownership of 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/customers/part-m-00001': User does not belong to supergroup
chgrp: changing ownership of 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/customers/part-m-00002': User does not belong to supergroup
chgrp: changing ownership of 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/customers/part-m-00003': User does not belong to supergroup
Table default.customers stats: [numFiles=4, totalSize=209050]


 ############################################################################################
 #1.1.2  Desde Sqoop cargar una tabla de MySQL en Hive creando la  desde el import de Sqoop.#
 ############################################################################################
 
[root@quickstart /]#sqoop import --connect jdbc:mysql://quickstart.cloudera:3306/retail_db --username root --password cloudera \
 --split-by order_id \
 --columns order_id,order_customer_id \
--table orders \
--target-dir /user/cloudera/ordersHive \
--fields-terminated-by "," \
--create-hive-table \
--hive-database default \
--hive-table ordersHive;

[root@quickstart /]# hadoop fs -ls -R /user/cloudera
drwxr-xr-x   - root cloudera          0 2018-03-26 09:24 /user/cloudera/ordersHive
-rw-r--r--   1 root cloudera          0 2018-03-26 09:24 /user/cloudera/ordersHive/_SUCCESS
-rw-r--r--   1 root cloudera     180100 2018-03-26 09:24 /user/cloudera/ordersHive/part-m-00000
-rw-r--r--   1 root cloudera     191247 2018-03-26 09:24 /user/cloudera/ordersHive/part-m-00001
-rw-r--r--   1 root cloudera     191374 2018-03-26 09:24 /user/cloudera/ordersHive/part-m-00002
-rw-r--r--   1 root cloudera     191330 2018-03-26 09:24 /user/cloudera/ordersHive/part-m-00003



