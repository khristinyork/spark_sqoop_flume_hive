%python
# Create Tables
# This notebook creates tables in Databricks from external files, primarily to make SQL access easier. 
# You can run this notebook yourself, but if you follow the lessons in order, one of the other notebooks will run this notebook for you.
None # suppress output

%python

from pathlib2 import Path

filePeople = "/mnt/training/dataframes/people-10m.parquet"
fileNames = "dbfs:/mnt/training/ssn/names.parquet"
fileBlog = "dbfs:/mnt/training/databricks-blog.json"
fileCity = "dbfs:/mnt/training/City-Data.parquet"
filePlane = "dbfs:/mnt/training/asa/planes/plane-data.csv"
fileSmall = "dbfs:/mnt/training/asa/flights/small.csv"
fileGeo = "dbfs:/mnt/training/ip-geocode.parquet"
fileBikes = "dbfs:/mnt/training/bikeSharing/data-001/day.csv"

dbutils.fs.ls(filePeople)
dbutils.fs.ls(fileNames)
dbutils.fs.ls(fileBlog)
dbutils.fs.ls(fileCity)
dbutils.fs.ls(filePlane)
dbutils.fs.ls(fileSmall)
dbutils.fs.ls(fileGeo)
dbutils.fs.ls(fileBikes)

None # suppress output

%python

def deleteTables() :
  try:
    tables=spark.catalog.listTables("Databricks")
  except:
    return
  for table in tables:
      spark.sql("DROP TABLE {}.{}".format("Databricks", table.name))
      
# deleteTables()
      
None # suppress output


%python

spark.sql("""
CREATE TABLE IF NOT EXISTS People10M
USING parquet
OPTIONS (
  path "{}"
)""".format(filePeople));

spark.sql("uncache TABLE People10M")

None # suppress output



%python

spark.sql("""
CREATE TABLE IF NOT EXISTS SSANames
USING parquet
OPTIONS (
  path "{}"
)""".format(fileNames))

spark.sql("uncache TABLE SSANames")

None # suppress output

%python

spark.sql("""
CREATE TABLE IF NOT EXISTS DatabricksBlog
USING json
OPTIONS (
  path "{}",
  inferSchema "true"
)""".format(fileBlog))

spark.sql("uncache TABLE DatabricksBlog")

None # suppress output

%python

spark.sql("""
CREATE TABLE IF NOT EXISTS CityData
USING parquet
OPTIONS (
  path "{}"
)""".format(fileCity))

spark.sql("uncache TABLE CityData")

None # suppress output

%python

spark.sql("""
CREATE TABLE IF NOT EXISTS AirlinePlane (`tailnum` STRING, `type` STRING, `manufacturer` STRING, `issue_date` STRING, `model` STRING, `status` STRING, `aircraft_type` STRING, `engine_type` STRING, `year` STRING)
USING csv 
OPTIONS (
  header "true",
  delimiter ",",
  inferSchema "false",
  path "{}"
)""".format(filePlane))

spark.sql("uncache TABLE AirlinePlane")

None # suppress output


%python

spark.sql("""
CREATE TABLE IF NOT EXISTS AirlineFlight (`Year` INT, `Month` INT, `DayofMonth` INT, `DayOfWeek` INT, `DepTime` STRING, `CRSDepTime` INT, `ArrTime` STRING, `CRSArrTime` INT, `UniqueCarrier` STRING, `FlightNum` INT, `TailNum` STRING, `ActualElapsedTime` STRING, `CRSElapsedTime` INT, `AirTime` STRING, `ArrDelay` STRING, `DepDelay` STRING, `Origin` STRING, `Dest` STRING, `Distance` INT, `TaxiIn` INT, `TaxiOut` INT, `Cancelled` INT, `CancellationCode` STRING, `Diverted` INT, `CarrierDelay` STRING, `WeatherDelay` STRING, `NASDelay` STRING, `SecurityDelay` STRING, `LateAircraftDelay` STRING)
USING CSV OPTIONS (
  header="true", 
  delimiter=",", 
  inferSchema="true", 
  path="{}")
""".format(fileSmall))

spark.sql("uncache TABLE AirlineFlight")

None # suppress output


%python

spark.sql("""
CREATE TABLE IF NOT EXISTS IPGeocode (`startingIP` DECIMAL(38,0), `endingIP` DECIMAL(38,0), `countryCode2` STRING, `countryCode3` STRING, `country` STRING, `stateProvince` STRING, `city` STRING, `latitude` DOUBLE, `longitude` DOUBLE)
USING parquet
OPTIONS (
  path "{}"
)
""".format(fileGeo))

spark.sql("uncache TABLE IPGeocode")

None # suppress output


%python

spark.sql("""
CREATE TABLE IF NOT EXISTS BikeSharingDay
USING csv
OPTIONS (
  path "{}",
  inferSchema "true",
  header "true"
)""".format(fileBikes))

spark.sql("uncache TABLE BikeSharingDay")

None # suppress output


